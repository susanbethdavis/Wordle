{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b17a4e61-0d4d-411a-b240-2e3e3170af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5946eafb-2ae9-43b0-adbc-c8949528d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'wordle_texts.csv'\n",
    "output_file_path = 'filtered_wordle_scores_per_day.csv'\n",
    "\n",
    "\n",
    "last_message_of_day = {}\n",
    "\n",
    "\n",
    "def is_valid_datetime(date_str):\n",
    "    try:\n",
    "        datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "with open(input_file_path, 'r', newline='', encoding='latin-1') as inp:\n",
    "    reader = csv.reader(inp)\n",
    "    \n",
    "    \n",
    "    header = next(reader)\n",
    "    \n",
    "    \n",
    "    for row in reader:\n",
    "        \n",
    "        if \"Tom \" in row[12] or \"tom \" in row[12]:\n",
    "            datetime_str = row[1]  \n",
    "            if is_valid_datetime(datetime_str):\n",
    "                timestamp = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')  \n",
    "                date_only = timestamp.date()  # \n",
    "                if date_only not in last_message_of_day or last_message_of_day[date_only][0] < timestamp:\n",
    "                    last_message_of_day[date_only] = (timestamp, row)\n",
    "\n",
    "\n",
    "with open(output_file_path, 'w', newline='', encoding='latin-1') as outp:\n",
    "    writer = csv.writer(outp)\n",
    "    \n",
    "    \n",
    "    writer.writerow(header)\n",
    "    \n",
    "    \n",
    "    for date in sorted(last_message_of_day.keys()):\n",
    "        writer.writerow(last_message_of_day[date][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d524eb9-3829-468d-945a-67cdc9a7e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filtered_wordle_scores_per_day.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f2ffcb0-0bed-4ede-8b13-9d5aa4cff33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Chat Session         Message Date Delivered Date  \\\n",
      "0   Ellen Davis & Dad  2023-07-19 22:36:36            NaN   \n",
      "1   Ellen Davis & Dad  2023-07-20 22:07:29            NaN   \n",
      "2   Ellen Davis & Dad  2023-07-21 12:42:07            NaN   \n",
      "3   Ellen Davis & Dad  2023-07-22 17:46:58            NaN   \n",
      "4   Ellen Davis & Dad  2023-07-23 09:06:14            NaN   \n",
      "..                ...                  ...            ...   \n",
      "95  Ellen Davis & Dad  2024-06-01 17:29:04            NaN   \n",
      "96  Ellen Davis & Dad  2024-06-02 13:14:35            NaN   \n",
      "97  Ellen Davis & Dad  2024-06-03 12:09:54            NaN   \n",
      "98  Ellen Davis & Dad  2024-06-04 14:14:20            NaN   \n",
      "99  Ellen Davis & Dad  2024-06-05 10:58:10            NaN   \n",
      "\n",
      "              Read Date  Edited Date Service      Type     Sender ID  \\\n",
      "0   2023-07-20 15:04:51          NaN     SMS  Incoming  1.919602e+10   \n",
      "1   2023-07-20 22:32:10          NaN     SMS  Incoming  1.919602e+10   \n",
      "2   2023-07-21 21:40:52          NaN     SMS  Incoming  1.919602e+10   \n",
      "3   2023-07-22 23:46:32          NaN     SMS  Incoming  1.919602e+10   \n",
      "4   2023-07-26 22:28:15          NaN     SMS  Incoming  1.919602e+10   \n",
      "..                  ...          ...     ...       ...           ...   \n",
      "95  2024-06-04 08:00:09          NaN     SMS  Incoming  1.919602e+10   \n",
      "96  2024-06-04 08:00:09          NaN     SMS  Incoming  1.919602e+10   \n",
      "97  2024-06-04 08:00:09          NaN     SMS  Incoming  1.919602e+10   \n",
      "98  2024-06-04 21:50:07          NaN     SMS  Incoming  1.919602e+10   \n",
      "99  2024-06-06 16:26:15          NaN     SMS  Incoming  1.919602e+10   \n",
      "\n",
      "   Sender Name Status  Replying to  Subject  \\\n",
      "0          Dad   Read          NaN      NaN   \n",
      "1          Dad   Read          NaN      NaN   \n",
      "2          Dad   Read          NaN      NaN   \n",
      "3          Dad   Read          NaN      NaN   \n",
      "4          Dad   Read          NaN      NaN   \n",
      "..         ...    ...          ...      ...   \n",
      "95         Dad   Read          NaN      NaN   \n",
      "96         Dad   Read          NaN      NaN   \n",
      "97         Dad   Read          NaN      NaN   \n",
      "98         Dad   Read          NaN      NaN   \n",
      "99         Dad   Read          NaN      NaN   \n",
      "\n",
      "                                                 Text  Attachment  \\\n",
      "0   Beth 5\\nEllen 5\\nLucy 4\\nTom 4\\nJen 3\\nPete 3\\...         NaN   \n",
      "1   Lucy 5\\nMarcos 5\\nPete 5\\nTom 5\\nJen 4\\nGrant ...         NaN   \n",
      "2            Beth 5\\nGrant 5\\nMarcos 5\\nPete 4\\nTom 4         NaN   \n",
      "3                     Pete 6\\nBeth 5\\nTom 5\\nMarcos 3         NaN   \n",
      "4                                       Pete 4\\nTom 3         NaN   \n",
      "..                                                ...         ...   \n",
      "95         Beth 4\\nGrant 4\\nNA = 3.6\\nMarcos 3\\nTom 3         NaN   \n",
      "96  Grant 6\\nTom 6\\nNA = 4.2\\nPete 4\\nMarcos 3\\nBe...         NaN   \n",
      "97  Smitty 5\\nLucy 4\\nMarcos 4\\nNA = 3.5\\nGrant 3\\...         NaN   \n",
      "98  Pete 6\\nJen 5\\nLucy 5\\nMarcos 5\\nTom 5\\nNA = 4...         NaN   \n",
      "99  Slim 5\\nSmitty 5\\nTom 5\\nMarcos 4\\nPete 4\\nNA ...         NaN   \n",
      "\n",
      "    Attachment type  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "..              ...  \n",
      "95              NaN  \n",
      "96              NaN  \n",
      "97              NaN  \n",
      "98              NaN  \n",
      "99              NaN  \n",
      "\n",
      "[100 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bb7c8a4-d1d0-4b97-8039-ef95347cc2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['Message Date', 'Text']\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fda2fbd-2438-4b27-9484-327e1144a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Message Date                                               Text\n",
      "0  2023-07-19 22:36:36  Beth 5\\nEllen 5\\nLucy 4\\nTom 4\\nJen 3\\nPete 3\\...\n",
      "1  2023-07-20 22:07:29  Lucy 5\\nMarcos 5\\nPete 5\\nTom 5\\nJen 4\\nGrant ...\n",
      "2  2023-07-21 12:42:07           Beth 5\\nGrant 5\\nMarcos 5\\nPete 4\\nTom 4\n",
      "3  2023-07-22 17:46:58                    Pete 6\\nBeth 5\\nTom 5\\nMarcos 3\n",
      "4  2023-07-23 09:06:14                                      Pete 4\\nTom 3\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bac044c2-d3ba-4425-8139-0e4623ed3691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Message Date  Year  Month  Day      Time  \\\n",
      "0   2023-07-19  2023      7   19  22:36:36   \n",
      "1   2023-07-20  2023      7   20  22:07:29   \n",
      "2   2023-07-21  2023      7   21  12:42:07   \n",
      "3   2023-07-22  2023      7   22  17:46:58   \n",
      "4   2023-07-23  2023      7   23  09:06:14   \n",
      "\n",
      "                                                Text  \n",
      "0  Beth 5\\nEllen 5\\nLucy 4\\nTom 4\\nJen 3\\nPete 3\\...  \n",
      "1  Lucy 5\\nMarcos 5\\nPete 5\\nTom 5\\nJen 4\\nGrant ...  \n",
      "2           Beth 5\\nGrant 5\\nMarcos 5\\nPete 4\\nTom 4  \n",
      "3                    Pete 6\\nBeth 5\\nTom 5\\nMarcos 3  \n",
      "4                                      Pete 4\\nTom 3  \n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Message Date' column to datetime\n",
    "df['Message Date'] = pd.to_datetime(df['Message Date'])\n",
    "\n",
    "# Extract year, month, day, and time\n",
    "df['Year'] = df['Message Date'].dt.year\n",
    "df['Month'] = df['Message Date'].dt.month\n",
    "df['Day'] = df['Message Date'].dt.day\n",
    "df['Time'] = df['Message Date'].dt.time\n",
    "df['Message Date'] = df['Message Date'].dt.date\n",
    "\n",
    "# Rearrange the columns\n",
    "df = df[['Message Date', 'Year', 'Month', 'Day', 'Time', 'Text']]\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(df.head())\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('wordle_texts_modified.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ae3bbaa-fd86-4acb-95d5-6f4d50e86f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Date    object\n",
      "Year             int32\n",
      "Month            int32\n",
      "Day              int32\n",
      "Time            object\n",
      "Text            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9c9ae-8ec4-4a83-8e17-1c848b21a162",
   "metadata": {},
   "source": [
    "MUST ADRESS: Sometimes dad sends update scores after 11:59 PM!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b9bd672-45da-43f4-8a15-980a6b96b1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded DataFrame:\n",
      "     Message Date  Year  Month  Day      Time      Text\n",
      "0      2023-07-19  2023      7   19  22:36:36    Beth 5\n",
      "1      2023-07-19  2023      7   19  22:36:36   Ellen 5\n",
      "2      2023-07-19  2023      7   19  22:36:36    Lucy 4\n",
      "3      2023-07-19  2023      7   19  22:36:36     Tom 4\n",
      "4      2023-07-19  2023      7   19  22:36:36     Jen 3\n",
      "...           ...   ...    ...  ...       ...       ...\n",
      "1077   2024-07-18  2024      7   18  14:34:00    Beth 5\n",
      "1078   2024-07-18  2024      7   18  14:34:00  Marcos 5\n",
      "1079   2024-07-18  2024      7   18  14:34:00     Tom 5\n",
      "1080   2024-07-18  2024      7   18  14:34:00  Smitty 3\n",
      "1081   2024-07-18  2024      7   18  14:34:00    Slim 4\n",
      "\n",
      "[1082 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split the text by new lines\n",
    "df['Text'] = df['Text'].apply(lambda x: x.split('\\n') if isinstance(x, str) else [])\n",
    "\n",
    "# Use explode to create new rows for each element in the list\n",
    "expanded_df = df.explode('Text').reset_index(drop=True)\n",
    "\n",
    "print(\"Expanded DataFrame:\")\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aee1de4c-5079-403a-8541-d9c56a2d2ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique counts by 'Message Date':\n",
      "Message Date\n",
      "2023-07-19    8\n",
      "2023-07-20    7\n",
      "2023-07-21    5\n",
      "2023-07-22    4\n",
      "2023-07-23    2\n",
      "             ..\n",
      "2024-07-14    6\n",
      "2024-07-15    7\n",
      "2024-07-16    8\n",
      "2024-07-17    6\n",
      "2024-07-18    5\n",
      "Length: 132, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_counts = expanded_df.groupby('Message Date').size()\n",
    "\n",
    "print(\"Unique counts by 'Message Date':\")\n",
    "print(unique_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5967223-b7d6-4cfb-81fc-48d0ec4a2b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Message Date  Year  Month  Day      Time      Text  Player Score\n",
      "0      2023-07-19  2023      7   19  22:36:36    Beth 5    Beth     5\n",
      "1      2023-07-19  2023      7   19  22:36:36   Ellen 5   Ellen     5\n",
      "2      2023-07-19  2023      7   19  22:36:36    Lucy 4    Lucy     4\n",
      "3      2023-07-19  2023      7   19  22:36:36     Tom 4     Tom     4\n",
      "4      2023-07-19  2023      7   19  22:36:36     Jen 3     Jen     3\n",
      "...           ...   ...    ...  ...       ...       ...     ...   ...\n",
      "1077   2024-07-18  2024      7   18  14:34:00    Beth 5    Beth     5\n",
      "1078   2024-07-18  2024      7   18  14:34:00  Marcos 5  Marcos     5\n",
      "1079   2024-07-18  2024      7   18  14:34:00     Tom 5     Tom     5\n",
      "1080   2024-07-18  2024      7   18  14:34:00  Smitty 3  Smitty     3\n",
      "1081   2024-07-18  2024      7   18  14:34:00    Slim 4    Slim     4\n",
      "\n",
      "[1082 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "expanded_df['Player'] = expanded_df['Text'].str.extract(r'^([A-Za-z]+)')\n",
    "expanded_df['Score'] = expanded_df['Text'].str.extract(r'(\\d+\\.?\\d*)$')\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e32c932-a0e0-4c09-b879-e55b31c623c7",
   "metadata": {},
   "source": [
    "# Deal with FAIL cases!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254595f2-c988-42a4-b527-50bdd67c37ca",
   "metadata": {},
   "source": [
    "Dr.Labarr sugested making a seperate column with a 0 for Non-fail and a 1 for Fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "96eeec5d-54ae-41f4-9204-a4fbbd3c8e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Message Date  Year  Month  Day      Time      Text  Player Score  Fail\n",
      "0      2023-07-19  2023      7   19  22:36:36    Beth 5    Beth     5     0\n",
      "1      2023-07-19  2023      7   19  22:36:36   Ellen 5   Ellen     5     0\n",
      "2      2023-07-19  2023      7   19  22:36:36    Lucy 4    Lucy     4     0\n",
      "3      2023-07-19  2023      7   19  22:36:36     Tom 4     Tom     4     0\n",
      "4      2023-07-19  2023      7   19  22:36:36     Jen 3     Jen     3     0\n",
      "...           ...   ...    ...  ...       ...       ...     ...   ...   ...\n",
      "1077   2024-07-18  2024      7   18  14:34:00    Beth 5    Beth     5     0\n",
      "1078   2024-07-18  2024      7   18  14:34:00  Marcos 5  Marcos     5     0\n",
      "1079   2024-07-18  2024      7   18  14:34:00     Tom 5     Tom     5     0\n",
      "1080   2024-07-18  2024      7   18  14:34:00  Smitty 3  Smitty     3     0\n",
      "1081   2024-07-18  2024      7   18  14:34:00    Slim 4    Slim     4     0\n",
      "\n",
      "[1082 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "expanded_df['Fail'] = expanded_df['Score'].isna().astype(int)\n",
    "\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e04b8-9619-473b-b269-d3b956afd89e",
   "metadata": {},
   "source": [
    "Lets add a column for start words used by different players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26b5d7af-d57f-4278-b8da-89956282dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA values in the 'Player' column with \"National Average\"\n",
    "expanded_df['Player'] = expanded_df['Player'].fillna('National Average')\n",
    "\n",
    "# Apply the case_when logic\n",
    "expanded_df['Player'] = expanded_df['Player'].replace({\n",
    "    'Idabelle': 'Isabelle',\n",
    "    'Isabele': 'Isabelle',\n",
    "    'Jen': 'Jennifer',\n",
    "    'Metedith': 'Meredith',\n",
    "    'NA': 'National Average'\n",
    "})\n",
    "\n",
    "\n",
    "start_words = {\n",
    "    'Beth': 'great',\n",
    "    'smitty': 'audio',\n",
    "    'grant': 'grant' ,\n",
    "    'pete': 'route',\n",
    "    'kate': 'ascot',\n",
    "    'Lucy': 'weird',\n",
    "    'Meredith': 'least',\n",
    "    'slim': 'games'\n",
    "}\n",
    "\n",
    "secondary_words = {\n",
    "    'Beth': 'pious',\n",
    "    'Lucy': 'nasty'}\n",
    "tertiary_words = {\n",
    "    'Lucy': 'cough'}\n",
    "expanded_df['Start_Words'] = expanded_df['Player'].map(start_words)\n",
    "expanded_df['secondary_words'] = expanded_df['Player'].map(secondary_words)\n",
    "expanded_df['tertiary_words'] = expanded_df['Player'].map(tertiary_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6577009e-507b-471a-a050-d15c7a1338a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Message Date  Year  Month  Day      Time      Text    Player Score  Fail  \\\n",
      "0      2023-07-19  2023      7   19  22:36:36    Beth 5      Beth     5     0   \n",
      "1      2023-07-19  2023      7   19  22:36:36   Ellen 5     Ellen     5     0   \n",
      "2      2023-07-19  2023      7   19  22:36:36    Lucy 4      Lucy     4     0   \n",
      "3      2023-07-19  2023      7   19  22:36:36     Tom 4       Tom     4     0   \n",
      "4      2023-07-19  2023      7   19  22:36:36     Jen 3  Jennifer     3     0   \n",
      "...           ...   ...    ...  ...       ...       ...       ...   ...   ...   \n",
      "1077   2024-07-18  2024      7   18  14:34:00    Beth 5      Beth     5     0   \n",
      "1078   2024-07-18  2024      7   18  14:34:00  Marcos 5    Marcos     5     0   \n",
      "1079   2024-07-18  2024      7   18  14:34:00     Tom 5       Tom     5     0   \n",
      "1080   2024-07-18  2024      7   18  14:34:00  Smitty 3    Smitty     3     0   \n",
      "1081   2024-07-18  2024      7   18  14:34:00    Slim 4      Slim     4     0   \n",
      "\n",
      "     Start_Words secondary_words tertiary_words  \n",
      "0          great           pious            NaN  \n",
      "1            NaN             NaN            NaN  \n",
      "2          weird           nasty          cough  \n",
      "3            NaN             NaN            NaN  \n",
      "4            NaN             NaN            NaN  \n",
      "...          ...             ...            ...  \n",
      "1077       great           pious            NaN  \n",
      "1078         NaN             NaN            NaN  \n",
      "1079         NaN             NaN            NaN  \n",
      "1080         NaN             NaN            NaN  \n",
      "1081         NaN             NaN            NaN  \n",
      "\n",
      "[1082 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ab33ae-3e8e-4fae-b652-b52892090563",
   "metadata": {},
   "source": [
    "Lets webscrape the previous wordle words for each day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15026996-5e53-4947-ae69-8eedbc81711c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb080f8d-ace4-4463-ae8d-4b9e21ded1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from tables 0 through 8 has been written to 'wordle_answers.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "URL = 'https://wordfinder.yourdictionary.com/wordle/answers/'\n",
    "req = requests.get(URL)\n",
    "soup = bs4.BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "HEADERS = ['Date', 'Wordle', 'Answer']\n",
    "\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "# would need to change range as new months are added to the website\n",
    "for table_index in range(9):\n",
    "    try:\n",
    "        table = soup.find_all('table')[table_index]\n",
    "        rows = table.find_all('tr')\n",
    "\n",
    "        #we start on first complete day. (I.E. if current day word is available, we dont grab it until tmr)\n",
    "        for row in rows[1:]: \n",
    "            cells = row.find_all('td')\n",
    "            Date = cells[0].text.strip() # why is year not grabbed?\n",
    "            Wordle = cells[1].text.strip()\n",
    "            Answer = cells[2].text.strip()\n",
    "            all_rows.append([Date, Wordle, Answer])\n",
    "\n",
    "    except IndexError:\n",
    "        print(f\"Table {table_index} does not exist on the page.\")\n",
    "\n",
    "\n",
    "with open('wordle_answers.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(HEADERS)\n",
    "    writer.writerows(all_rows)\n",
    "\n",
    "print(f\"Data from tables 0 through 8 has been written to 'wordle_answers.csv'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8788a718-3f53-44f7-8e49-cc7f350ea112",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = pd.read_csv('wordle_answers.csv')\n",
    "answers = answers.drop(0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3a863-2ec3-4fe9-82c9-a2175cf2215a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d37e0fbe-89fb-4c26-9304-d49ac001dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  Wordle Answer\n",
      "0    2024-07-19    1126  REFER\n",
      "1    2024-07-18    1125  NERDY\n",
      "2    2024-07-17    1124  QUITE\n",
      "3    2024-07-16    1123  DECOY\n",
      "4    2024-07-15    1122  SWOON\n",
      "..          ...     ...    ...\n",
      "257  2023-11-05     869  FLARE\n",
      "258  2023-11-04     868  MANIA\n",
      "259  2023-11-03     867  ARDOR\n",
      "260  2023-11-02     866  UNTIL\n",
      "261  2023-11-01     865  NOISE\n",
      "\n",
      "[262 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# why is the 30th and 31st of each month?????\n",
    "month_map = {\n",
    "    'Jan': '01',\n",
    "    'Feb': '02',\n",
    "    'Mar': '03',\n",
    "    'Apr': '04',\n",
    "    'May': '05',\n",
    "    'Jun': '06',\n",
    "    'Jul': '07',\n",
    "    'Aug': '08',\n",
    "    'Sep': '09',\n",
    "    'Oct': '10',\n",
    "    'Nov': '11',\n",
    "    'Dec': '12'\n",
    "}\n",
    "\n",
    "# Function to transform the date format\n",
    "def transform_date(date_str, wordle_number):\n",
    "    # Remove the period after the month and split by space\n",
    "    parts = date_str.replace('.', '').split()\n",
    "    # Ensure parts has exactly two elements\n",
    "    if len(parts) != 2:\n",
    "        raise ValueError(f\"Date string format is incorrect: {date_str}\")\n",
    "    # Map the month name to its corresponding number\n",
    "    month_number = month_map[parts[0]]\n",
    "    # Determine the year based on the Wordle Answer number\n",
    "    year = 2024 if wordle_number >= 926 else 2023 # looked up this value from website\n",
    "    return f\"{year}-{month_number}-{parts[1]}\"\n",
    "\n",
    "# Apply the function to the 'Date' column\n",
    "answers['Date'] = answers.apply(lambda row: transform_date(row['Date'], row['Wordle']), axis=1)\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a3d023d-04ab-46ff-a5ec-c16759006393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2024-07-19': 'REFER', '2024-07-18': 'NERDY', '2024-07-17': 'QUITE', '2024-07-16': 'DECOY', '2024-07-15': 'SWOON', '2024-07-14': 'VIDEO', '2024-07-13': 'ENACT', '2024-07-12': 'JIFFY', '2024-07-11': 'CAMEO', '2024-07-10': 'GAUNT', '2024-07-09': 'BLARE', '2024-07-08': 'SHAPE', '2024-07-07': 'CANON', '2024-07-06': 'SCOFF', '2024-07-05': 'CRUSH', '2024-07-04': 'DEBUT', '2024-07-03': 'THIGH', '2024-07-02': 'INLAY', '2024-07-01': 'ADAGE', '2024-06-30': 'BUDDY', '2024-06-29': 'ZEBRA', '2024-06-28': 'DROVE', '2024-06-27': 'ORDER', '2024-06-26': 'KNEAD', '2024-06-25': 'SAVOR', '2024-06-24': 'DOLLY', '2024-06-23': 'BUGLE', '2024-06-22': 'EDICT', '2024-06-21': 'PAINT', '2024-06-20': 'SCENT', '2024-06-19': 'TERSE', '2024-06-18': 'COVER', '2024-06-17': 'PRIOR', '2024-06-16': 'GRIND', '2024-06-15': 'PROUD', '2024-06-14': 'VAULT', '2024-06-13': 'ANGST', '2024-06-12': 'DETER', '2024-06-11': 'SWUNG', '2024-06-10': 'MANGA', '2024-06-09': 'CROWD', '2024-06-08': 'HENCE', '2024-06-07': 'MELON', '2024-06-06': 'ETHER', '2024-06-05': 'ORGAN', '2024-06-04': 'GROOM', '2024-06-03': 'STARK', '2024-06-02': 'BRAVO', '2024-06-01': 'BASIN', '2024-05-31': 'CHAOS', '2024-05-30': 'GUMMY', '2024-05-29': 'PAPAL', '2024-05-28': 'MINUS', '2024-05-27': 'SKIER', '2024-05-26': 'BEVEL', '2024-05-25': 'TITAN', '2024-05-24': 'GLIDE', '2024-05-23': 'SWISH', '2024-05-22': 'EXALT', '2024-05-21': 'DINGO', '2024-05-20': 'NICER', '2024-05-19': 'HITCH', '2024-05-18': 'BRINY', '2024-05-17': 'TUTOR', '2024-05-16': 'STALL', '2024-05-15': 'PINCH', '2024-05-14': 'AMASS', '2024-05-13': 'CUMIN', '2024-05-12': 'OUTER', '2024-05-11': 'TIDAL', '2024-05-10': 'MEDIA', '2024-05-09': 'JERKY', '2024-05-08': 'PIOUS', '2024-05-07': 'MUSTY', '2024-05-06': 'SHAVE', '2024-05-05': 'DECAL', '2024-05-04': 'VALUE', '2024-05-03': 'EBONY', '2024-05-02': 'SLICE', '2024-05-01': 'DIARY', '2024-04-30': 'PROWL', '2024-04-29': 'CRAFT', '2024-04-28': 'PRUNE', '2024-04-27': 'GLEAM', '2024-04-26': 'VAPID', '2024-04-25': 'INTRO', '2024-04-24': 'OVERT', '2024-04-23': 'ROVER', '2024-04-22': 'LASER', '2024-04-21': 'JOLLY', '2024-04-20': 'LUCID', '2024-04-19': 'RAISE', '2024-04-18': 'FACET', '2024-04-17': 'TITHE', '2024-04-16': 'SHANK', '2024-04-15': 'EQUIP', '2024-04-14': 'BLIMP', '2024-04-13': 'STEEL', '2024-04-12': 'WHINY', '2024-04-11': 'LOUSE', '2024-04-10': 'BROTH', '2024-04-09': 'MERGE', '2024-04-08': 'BREED', '2024-04-07': 'VOILA', '2024-04-06': 'FINCH', '2024-04-05': 'WRIST', '2024-04-04': 'CLIMB', '2024-04-03': 'PLAIT', '2024-04-02': 'SERUM', '2024-04-01': 'FROND', '2024-03-31': 'TABOO', '2024-03-30': 'FORCE', '2024-03-29': 'REALM', '2024-03-28': 'SPEAK', '2024-03-27': 'STUNG', '2024-03-26': 'MAYOR', '2024-03-25': 'SALLY', '2024-03-24': 'TOWEL', '2024-03-23': 'RISEN', '2024-03-22': 'DECAY', '2024-03-21': 'SHADE', '2024-03-20': 'LINGO', '2024-03-19': 'ABIDE', '2024-03-18': 'SPELT', '2024-03-17': 'SNORT', '2024-03-16': 'TOXIN', '2024-03-15': 'ERUPT', '2024-03-14': 'SINCE', '2024-03-13': 'LOCAL', '2024-03-12': 'HEAVE', '2024-03-11': 'PESKY', '2024-03-10': 'GRASP', '2024-03-09': 'CHEER', '2024-03-08': 'EARLY', '2024-03-07': 'CLONE', '2024-03-06': 'TEARY', '2024-03-05': 'HUNCH', '2024-03-04': 'FLAME', '2024-03-03': 'STATE', '2024-03-02': 'URBAN', '2024-03-01': 'FORTY', '2024-02-29': 'IMAGE', '2024-02-28': 'DEVIL', '2024-02-27': 'SENSE', '2024-02-26': 'OFTEN', '2024-02-25': 'SMITH', '2024-02-24': 'PIPER', '2024-02-23': 'APART', '2024-02-22': 'HEAVY', '2024-02-21': 'BUILD', '2024-02-20': 'MATCH', '2024-02-19': 'PRICE', '2024-02-18': 'RIDGE', '2024-02-17': 'PSALM', '2024-02-16': 'STASH', '2024-02-15': 'ASCOT', '2024-02-14': 'TALON', '2024-02-13': 'SCRAM', '2024-02-12': 'PASTA', '2024-02-11': 'NEVER', '2024-02-10': 'FRIED', '2024-02-09': 'STIFF', '2024-02-08': 'PLACE', '2024-02-07': 'AFTER', '2024-02-06': 'WHICH', '2024-02-05': 'REPEL', '2024-02-04': 'VERGE', '2024-02-03': 'MICRO', '2024-02-02': 'CLEFT', '2024-02-01': 'ALIVE', '2024-01-31': 'BULKY', '2024-01-30': 'EXPEL', '2024-01-29': 'LEGGY', '2024-01-28': 'EMBER', '2024-01-27': 'SNAKE', '2024-01-26': 'ALOOF', '2024-01-25': 'BLOCK', '2024-01-24': 'RELIC', '2024-01-23': 'STILL', '2024-01-22': 'TWEAK', '2024-01-21': 'NORTH', '2024-01-20': 'LARGE', '2024-01-19': 'THING', '2024-01-18': 'STOLE', '2024-01-17': 'COURT', '2024-01-16': 'BLOND', '2024-01-15': 'LUNCH', '2024-01-14': 'DOING', '2024-01-13': 'HEARD', '2024-01-12': 'ROUTE', '2024-01-11': 'BRIEF', '2024-01-10': 'THREW', '2024-01-09': 'LINER', '2024-01-08': 'FINAL', '2024-01-07': 'STONY', '2024-01-06': 'CABLE', '2024-01-05': 'LUNGE', '2024-01-04': 'SCANT', '2024-01-03': 'TWIRL', '2024-01-02': 'AGING', '2024-01-01': 'MURAL', '2023-12-31': 'SALTY', '2023-12-30': 'THREE', '2023-12-29': 'CHILD', '2023-12-28': 'LEARN', '2023-12-27': 'DAISY', '2023-12-26': 'PHONE', '2023-12-25': 'EVOKE', '2023-12-24': 'GRACE', '2023-12-23': 'SLOPE', '2023-12-22': 'TOUCH', '2023-12-21': 'BUILT', '2023-12-20': 'SMALL', '2023-12-19': 'TABLE', '2023-12-18': 'FUNNY', '2023-12-17': 'BACON', '2023-12-16': 'GLOBE', '2023-12-15': 'TOPIC', '2023-12-14': 'WOULD', '2023-12-13': 'SPENT', '2023-12-12': 'THESE', '2023-12-11': 'HOUSE', '2023-12-10': 'CHAIN', '2023-12-09': 'SHIFT', '2023-12-08': 'SHARP', '2023-12-07': 'SLEEP', '2023-12-06': 'WOMAN', '2023-12-05': 'YOUNG', '2023-12-04': 'WORST', '2023-12-03': 'ADAPT', '2023-12-02': 'GENRE', '2023-12-01': 'TAKEN', '2023-11-30': 'RESIN', '2023-11-29': 'SUSHI', '2023-11-28': 'SCOPE', '2023-11-27': 'TAWNY', '2023-11-26': 'SOLID', '2023-11-25': 'GUIDE', '2023-11-24': 'THROW', '2023-11-23': 'QUEEN', '2023-11-22': 'PIXEL', '2023-11-21': 'PIANO', '2023-11-20': 'CANDY', '2023-11-19': 'QUEUE', '2023-11-18': 'THINK', '2023-11-17': 'TARDY', '2023-11-16': 'TRUST', '2023-11-15': 'SIGHT', '2023-11-14': 'SASSY', '2023-11-13': 'GREEN', '2023-11-12': 'MEANT', '2023-11-11': 'ACTOR', '2023-11-10': 'LEASH', '2023-11-09': 'GLAZE', '2023-11-08': 'NINJA', '2023-11-07': 'LIMIT', '2023-11-06': 'TRADE', '2023-11-05': 'FLARE', '2023-11-04': 'MANIA', '2023-11-03': 'ARDOR', '2023-11-02': 'UNTIL', '2023-11-01': 'NOISE'}\n"
     ]
    }
   ],
   "source": [
    "answers_dictionary = {}\n",
    "\n",
    "# Loop through each row index\n",
    "for i in range(len(answers)):\n",
    "    date = answers.iloc[i, 0]  # Assuming the first column is 'Date'\n",
    "    answer = answers.iloc[i, 2]  # Assuming third column is 'Answer'\n",
    "    \n",
    "    answers_dictionary[date] = answer\n",
    "\n",
    "print(answers_dictionary )\n",
    "\n",
    "answers_dictionary = {datetime.strptime(k, '%Y-%m-%d'): v for k, v in answers_dictionary.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ff203e8-5596-4545-8816-77aae8ba4de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Message Date  Year  Month  Day      Time      Text    Player Score  Fail  \\\n",
      "0      2023-07-19  2023      7   19  22:36:36    Beth 5      Beth     5     0   \n",
      "1      2023-07-19  2023      7   19  22:36:36   Ellen 5     Ellen     5     0   \n",
      "2      2023-07-19  2023      7   19  22:36:36    Lucy 4      Lucy     4     0   \n",
      "3      2023-07-19  2023      7   19  22:36:36     Tom 4       Tom     4     0   \n",
      "4      2023-07-19  2023      7   19  22:36:36     Jen 3  Jennifer     3     0   \n",
      "...           ...   ...    ...  ...       ...       ...       ...   ...   ...   \n",
      "1077   2024-07-18  2024      7   18  14:34:00    Beth 5      Beth     5     0   \n",
      "1078   2024-07-18  2024      7   18  14:34:00  Marcos 5    Marcos     5     0   \n",
      "1079   2024-07-18  2024      7   18  14:34:00     Tom 5       Tom     5     0   \n",
      "1080   2024-07-18  2024      7   18  14:34:00  Smitty 3    Smitty     3     0   \n",
      "1081   2024-07-18  2024      7   18  14:34:00    Slim 4      Slim     4     0   \n",
      "\n",
      "     Start_Words secondary_words tertiary_words wordle_answers  \n",
      "0          great           pious            NaN            NaN  \n",
      "1            NaN             NaN            NaN            NaN  \n",
      "2          weird           nasty          cough            NaN  \n",
      "3            NaN             NaN            NaN            NaN  \n",
      "4            NaN             NaN            NaN            NaN  \n",
      "...          ...             ...            ...            ...  \n",
      "1077       great           pious            NaN          NERDY  \n",
      "1078         NaN             NaN            NaN          NERDY  \n",
      "1079         NaN             NaN            NaN          NERDY  \n",
      "1080         NaN             NaN            NaN          NERDY  \n",
      "1081         NaN             NaN            NaN          NERDY  \n",
      "\n",
      "[1082 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "expanded_df['wordle_answers'] = expanded_df['Message Date'].map(answers_dictionary)\n",
    "print(expanded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f118dcf-a189-4a01-a341-3738203774a9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e187857b-6815-4533-bf55-05ef26a7bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df.to_csv('expanded_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
